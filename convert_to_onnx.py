"""
PyTorch ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
ì‚¬ìš©ë²•: python convert_to_onnx.py
"""

import torch
import torch.nn as nn

# ëª¨ë¸ êµ¬ì¡° ì •ì˜ (ì‹¤ì œ ëª¨ë¸ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”)
class YourModel(nn.Module):
    def __init__(self, num_classes):
        super(YourModel, self).__init__()
        # ì˜ˆì‹œ: ResNet ê¸°ë°˜ ëª¨ë¸
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),
            # ... ì¶”ê°€ ë ˆì´ì–´ë“¤
        )
        self.classifier = nn.Linear(512, num_classes)
    
    def forward(self, x):
        x = self.features(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x

# ì„¤ì •
NUM_CLASSES = 10  # í´ë˜ìŠ¤ ê°œìˆ˜ì— ë§ê²Œ ìˆ˜ì •
MODEL_PATH = 'ai/my_model.pth'
OUTPUT_PATH = 'ai/my_model.onnx'

def convert_to_onnx():
    # ëª¨ë¸ ë¡œë“œ
    model = YourModel(num_classes=NUM_CLASSES)
    
    # .pth íŒŒì¼ ë¡œë“œ
    checkpoint = torch.load(MODEL_PATH, map_location='cpu')
    
    # state_dict ë¡œë“œ (ì €ì¥ ë°©ì‹ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
    if isinstance(checkpoint, dict):
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        elif 'state_dict' in checkpoint:
            model.load_state_dict(checkpoint['state_dict'])
        else:
            model.load_state_dict(checkpoint)
    else:
        model.load_state_dict(checkpoint)
    
    model.eval()
    
    # ë”ë¯¸ ì…ë ¥ ìƒì„± (ë°°ì¹˜=1, ì±„ë„=3, ë†’ì´=224, ë„ˆë¹„=224)
    dummy_input = torch.randn(1, 3, 224, 224)
    
    # ONNXë¡œ ë³€í™˜
    torch.onnx.export(
        model,
        dummy_input,
        OUTPUT_PATH,
        export_params=True,
        opset_version=11,
        do_constant_folding=True,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={
            'input': {0: 'batch_size'},
            'output': {0: 'batch_size'}
        }
    )
    
    print(f"âœ… ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤: {OUTPUT_PATH}")
    
    # ì™¸ë¶€ ë°ì´í„° íŒŒì¼ì„ ëª¨ë¸ì— í¬í•¨ì‹œí‚¤ê¸° (ì›¹ ë¸Œë¼ìš°ì € í˜¸í™˜ì„±ì„ ìœ„í•´)
    import onnx
    onnx_model = onnx.load(OUTPUT_PATH)
    
    # ì™¸ë¶€ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ëª¨ë¸ ë‚´ë¶€ë¡œ í¬í•¨
    onnx.save(onnx_model, OUTPUT_PATH, save_as_external_data=False)
    
    # ë³€í™˜ í™•ì¸
    onnx.checker.check_model(onnx_model)
    print("âœ… ONNX ëª¨ë¸ ê²€ì¦ ì™„ë£Œ")
    print("ğŸ’¡ ëª¨ë¸ì´ ë‹¨ì¼ íŒŒì¼ë¡œ ì €ì¥ë˜ì–´ ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")

if __name__ == '__main__':
    convert_to_onnx()
